import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.core.classification.efficientnet_inference import EfficientNetInference

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½æ˜¯å¦æˆåŠŸ"""
    print("å¼€å§‹æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    try:
        # åˆå§‹åŒ–æ¨ç†å™¨
        infer = EfficientNetInference()
        
        # æ£€æŸ¥ç±»åˆ«æ•°é‡
        num_classes = len(infer.classes)
        print(f"ç±»åˆ«æ•°é‡: {num_classes}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æˆåŠŸåŠ è½½
        if infer.model is not None:
            print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        else:
            print("âœ— æ¨¡å‹åŠ è½½å¤±è´¥ï¼")
            return False
        
        # æ£€æŸ¥ç±»åˆ«æ•°é‡æ˜¯å¦ä¸æ¨¡å‹ä¸€è‡´
        # è·å–æ¨¡å‹æœ€åä¸€å±‚çš„è¾“å‡ºç»´åº¦
        import torch
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 224, 224).to(infer.device)
            output = infer.model(dummy_input)
            model_output_dim = output.shape[1]
            print(f"æ¨¡å‹è¾“å‡ºç»´åº¦: {model_output_dim}")
            
        if num_classes == model_output_dim:
            print(f"âœ“ ç±»åˆ«æ•°é‡åŒ¹é…: {num_classes} = {model_output_dim}")
            return True
        else:
            print(f"âœ— ç±»åˆ«æ•°é‡ä¸åŒ¹é…: {num_classes} != {model_output_dim}")
            return False
            
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_model_loading()
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹åŠ è½½ä¿®å¤æˆåŠŸï¼")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
